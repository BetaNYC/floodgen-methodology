{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from addict import Dict\n",
    "from torch.nn import init\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# -----  For now no network structure, just project in a 64 x 32 x 32  -----\n",
    "# -----   latent space and decode to (3 or 1) x 256 x 256              -----\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def get_gen(opts):\n",
    "    G = Generator(opts)\n",
    "    G.init_weights()\n",
    "    return G\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, opts):\n",
    "        super().__init__()\n",
    "        self.project = nn.Conv2d(3, 64, 1)\n",
    "        self.downsample = nn.AdaptiveMaxPool2d(32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.project(self.downsample(x))\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, opts):\n",
    "        \"\"\"Creates the generator. All decoders listed in opts.gen will be added\n",
    "        to the Generator.decoders ModuleDict if opts.gen.DecoderInitial is not True.\n",
    "        Then can be accessed as G.decoders.T or G.decoders[\"T\"] for instance,\n",
    "        for the image Translation decoder\n",
    "\n",
    "        Args:\n",
    "            opts (addict.Dict): configuration dict\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.E = Encoder(opts)\n",
    "\n",
    "        self.decoders = {}\n",
    "\n",
    "        if \"A\" in opts.gen and not opts.gen.A.ignore:\n",
    "            self.decoders[\"A\"] = nn.ModuleDict(\n",
    "                {\"real\": AdapatationDecoder(opts), \"sim\": AdapatationDecoder(opts)}\n",
    "            )\n",
    "\n",
    "        if \"D\" in opts.gen and not opts.gen.D.ignore:\n",
    "            self.decoders[\"D\"] = DepthDecoder(opts)\n",
    "\n",
    "        if \"H\" in opts.gen and not opts.gen.H.ignore:\n",
    "            self.decoders[\"H\"] = HeightDecoder(opts)\n",
    "\n",
    "        if \"T\" in opts.gen and not opts.gen.T.ignore:\n",
    "            self.decoders[\"T\"] = nn.ModuleDict(\n",
    "                {\"f\": TranslationDecoder(opts), \"nf\": TranslationDecoder(opts)}\n",
    "            )\n",
    "\n",
    "        if \"W\" in opts.gen and not opts.gen.W.ignore:\n",
    "            self.decoders[\"W\"] = WaterDecoder(opts)\n",
    "\n",
    "        self.decoders = nn.ModuleDict(self.decoders)\n",
    "\n",
    "    def init_weights(self, init_type=\"normal\", init_gain=0.02):\n",
    "        \"\"\"Initialize network weights.\n",
    "        Parameters:\n",
    "            net (network)     -- network to be initialized\n",
    "            init_type (str)   -- the name of an initialization method:\n",
    "                                 normal | xavier | kaiming | orthogonal\n",
    "            init_gain (float) -- scaling factor for normal, xavier and orthogonal.\n",
    "\n",
    "        We use 'normal' in the original pix2pix and CycleGAN paper.\n",
    "        But xavier and kaiming might work better for some applications.\n",
    "        Feel free to try yourself.\n",
    "        \"\"\"\n",
    "\n",
    "        def init_func(m):  # define the initialization function\n",
    "            classname = m.__class__.__name__\n",
    "            if hasattr(m, \"weight\") and (\n",
    "                classname.find(\"Conv\") != -1 or classname.find(\"Linear\") != -1\n",
    "            ):\n",
    "                if init_type == \"normal\":\n",
    "                    init.normal_(m.weight.data, 0.0, init_gain)\n",
    "                elif init_type == \"xavier\":\n",
    "                    init.xavier_normal_(m.weight.data, gain=init_gain)\n",
    "                elif init_type == \"kaiming\":\n",
    "                    init.kaiming_normal_(m.weight.data, a=0, mode=\"fan_in\")\n",
    "                elif init_type == \"orthogonal\":\n",
    "                    init.orthogonal_(m.weight.data, gain=init_gain)\n",
    "                else:\n",
    "                    raise NotImplementedError(\n",
    "                        \"initialization method [%s] is not implemented\" % init_type\n",
    "                    )\n",
    "                if hasattr(m, \"bias\") and m.bias is not None:\n",
    "                    init.constant_(m.bias.data, 0.0)\n",
    "            elif classname.find(\"BatchNorm2d\") != -1:\n",
    "                # BatchNorm Layer's weight is not a matrix;\n",
    "                # only normal distribution applies.\n",
    "                init.normal_(m.weight.data, 1.0, init_gain)\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "        print(\"initialize network with %s\" % init_type)\n",
    "        self.apply(init_func)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"generic class for decoders\n",
    "    \"\"\"\n",
    "    def __init__(self, opts):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class HeightDecoder(Decoder):\n",
    "    def __init__(self, opts):\n",
    "        super().__init__(opts)\n",
    "        self.layers = []\n",
    "        self.layers.append(nn.Conv2d(64, 1, 1))\n",
    "        self.layers.append(nn.UpsamplingNearest2d(256))\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "\n",
    "\n",
    "class WaterDecoder(Decoder):\n",
    "    def __init__(self, opts):\n",
    "        super().__init__(opts)\n",
    "        self.layers = []\n",
    "        self.layers.append(nn.Conv2d(64, 1, 1))\n",
    "        self.layers.append(nn.UpsamplingNearest2d(256))\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "\n",
    "\n",
    "class DepthDecoder(Decoder):\n",
    "    def __init__(self, opts):\n",
    "        super().__init__(opts)\n",
    "        self.layers = []\n",
    "        self.layers.append(nn.Conv2d(64, 1, 1))\n",
    "        self.layers.append(nn.UpsamplingNearest2d(256))\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "\n",
    "\n",
    "class TranslationDecoder(Decoder):\n",
    "    def __init__(self, opts):\n",
    "        super().__init__(opts)\n",
    "        self.layers = []\n",
    "        self.layers.append(nn.Conv2d(64, 3, 1))\n",
    "        self.layers.append(nn.UpsamplingNearest2d(256))\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "\n",
    "\n",
    "class AdapatationDecoder(Decoder):\n",
    "    def __init__(self, opts):\n",
    "        super().__init__(opts)\n",
    "        self.layers = []\n",
    "        self.layers.append(nn.Conv2d(64, 3, 1))\n",
    "        self.layers.append(nn.UpsamplingNearest2d(256))\n",
    "        self.layers = nn.Sequential(*self.layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "opts = Dict()\n",
    "\n",
    "batch_size = 7\n",
    "latent_space_dims = [64, 32, 32]\n",
    "\n",
    "image = torch.randn(batch_size, 3, 256, 256)\n",
    "\n",
    "test_partial_decoder = True\n",
    "test_encoder = True\n",
    "test_encode_decode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "False\n",
      "True\n",
      "torch.Size([7, 1, 256, 256])\n",
      "910\n"
     ]
    }
   ],
   "source": [
    "if test_partial_decoder:\n",
    "    opts.gen.A.ignore = False\n",
    "    opts.gen.D.ignore = True\n",
    "    opts.gen.H.ignore = False\n",
    "    opts.gen.T.ignore = False\n",
    "    opts.gen.W.ignore = False\n",
    "    G = Generator(opts)\n",
    "    G.init_weights()\n",
    "    print('D' in G.decoders)\n",
    "    print('A' in G.decoders)\n",
    "    x = torch.randn(batch_size, *latent_space_dims, dtype=torch.float32)\n",
    "    v = G.decoders[\"W\"](x)\n",
    "    print(v.shape)\n",
    "    print(sum(p.numel() for p in G.decoders.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "ModuleDict(\n",
      "  (A): ModuleDict(\n",
      "    (real): AdapatationDecoder(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): UpsamplingNearest2d(size=256, mode=nearest)\n",
      "      )\n",
      "    )\n",
      "    (sim): AdapatationDecoder(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): UpsamplingNearest2d(size=256, mode=nearest)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (D): DepthDecoder(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): UpsamplingNearest2d(size=256, mode=nearest)\n",
      "    )\n",
      "  )\n",
      "  (H): HeightDecoder(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): UpsamplingNearest2d(size=256, mode=nearest)\n",
      "    )\n",
      "  )\n",
      "  (T): ModuleDict(\n",
      "    (f): TranslationDecoder(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): UpsamplingNearest2d(size=256, mode=nearest)\n",
      "      )\n",
      "    )\n",
      "    (nf): TranslationDecoder(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): UpsamplingNearest2d(size=256, mode=nearest)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (W): WaterDecoder(\n",
      "    (layers): Sequential(\n",
      "      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): UpsamplingNearest2d(size=256, mode=nearest)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Encoder(\n",
      "  (project): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (downsample): AdaptiveMaxPool2d(output_size=32)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "opts.gen.A.ignore = False\n",
    "opts.gen.D.ignore = False\n",
    "opts.gen.H.ignore = False\n",
    "opts.gen.T.ignore = False\n",
    "opts.gen.W.ignore = False\n",
    "\n",
    "G = Generator(opts)\n",
    "G.init_weights()\n",
    "print(G.decoders)\n",
    "print(G.E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "if test_encoder:\n",
    "    encoded = G.E(image)\n",
    "    print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A real torch.Size([7, 3, 256, 256])\n",
      "A sim torch.Size([7, 3, 256, 256])\n",
      "D torch.Size([7, 1, 256, 256])\n",
      "T f torch.Size([7, 3, 256, 256])\n",
      "T nf torch.Size([7, 3, 256, 256])\n",
      "H torch.Size([7, 1, 256, 256])\n",
      "W torch.Size([7, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "if test_encode_decode:\n",
    "    z = G.E(image)\n",
    "    for dec in \"ADTHW\":\n",
    "        if dec in G.decoders:\n",
    "            if dec in \"AT\":\n",
    "                for d in G.decoders[dec]:\n",
    "                    print(dec, d, G.decoders[dec][d](z).shape)\n",
    "            else:\n",
    "                print(dec, G.decoders[dec](z).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
